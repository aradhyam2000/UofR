---
output:
  pdf_document: default
  html_document: default
---
---
title: "DSCC/CSC/STAT 462 Assignment 5- Aradhya Mathur"
output:
  pdf_document: default
  html_document:
    df_print: paged
subtitle: Due December 1, 2022 by 11:59 p.m.
fontsize: 12pt
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, eval=T,tidy=TRUE, tidy.opts=list(width.cutoff=60))
```
  
\vspace{5pt}
Please complete this assignment using `RMarkdown`, and submit the knitted PDF.
*For all hypothesis tests, state the hypotheses, report the test statistic and  
p-value, and comment on the results in the context of the problem.* 
\vspace{5pt}

1. The dataset "actg.csv" contains data on subjects who were enrolled in a HIV 
clinical trial. For this dataset, we are focusing on variables ``IVDrug`` and 
``Age``. ``IVDrug`` is a categorical variable that indicates whether each subject
never, previously, or currently uses IV drugs. ``Age`` lists the subject's age 
in year. Thus, we have age for subjects in three treatment groups. Assume that 
the samples were collected independently and come from normally distributed populations.

```{r}
actg <-  read.csv('actg.csv.')
head(actg)
```

    a. Create side-by-side boxplots of age by IV use group. Does the equal 
    variance assumption seem reasonable?
    
```{r}
library(ggplot2)
box_plot <<-ggplot(data=actg, aes(y= Age, x=IVDrug, fill=IVDrug ))
box_plot <- box_plot + geom_boxplot()
box_plot <- box_plot + ggtitle("HIV Clinical Trial") 
box_plot <- box_plot +  ylab("Age") + xlab("IV Drug") 
box_plot 
```
    
    Yes, equal variance assumption seems reasonable.
    
    b. Construct an ANOVA table to test at the $\alpha=0.05$ significance level 
    whether the average age in these three groups is different.  
    
    Null Hypothesis: Average age in these groups are same.
    H1 : Average age in these groups are different. Atleast two groups have 
    different age
    
```{r}
Y = actg$Age
X = actg$IVDrug
model1=aov(Y~X)
anova(model1)
```
    F val = 72.452
    P val = 2.2e-16
    P values are small and so reject null hypothesis . Average age are different 
    in atleast two groups
    
    
```{r}
never <- subset(actg,IVDrug=="Never" , select=c("Age"))
currently <- subset(actg,IVDrug=="Currently" , select=c("Age"))
previously <- subset(actg,IVDrug=="Previously" , select=c("Age"))

lennever=length(never$Age)
unever=mean(never$Age)
sdnever=sd(never$Age)
lencurrently<-length(currently$Age)
ucurrently<-mean(currently$Age)
sdcurrently<-sd(currently$Age)
lenpreviously<-length(previously$Age)
upreviously<-mean(previously$Age)
sdpreviously<-sd(previously$Age)
xbar=((lencurrently*ucurrently) + (lennever*unever) + (lenpreviously*upreviously))/(lencurrently+lennever+lenpreviously)
sw=(((lencurrently-1)*(sdcurrently)^2)+((lennever-1)*(sdnever)^2)+((lenpreviously-1)*(sdpreviously)^2))/(lencurrently+lennever+lenpreviously-3)
n1 = 3-1
sb=((lencurrently*(ucurrently-xbar)^2)+(lennever*(unever-xbar)^2)+(lenpreviously*(upreviously-xbar)^2))/(n1)
sst=sw+sb
f=sb/sw
print(paste(f, "is F value"))
n2=lencurrently+lennever+lenpreviously-3
p_value=1-pf(f,2,n2)
print(paste(p_value, "is P value"))
swnum = ((lencurrently-1)*(sdcurrently)^2)+((lennever-1)*(sdnever)^2)+((lenpreviously-1)*(sdpreviously)^2)
swden = (lencurrently+lennever+lenpreviously-3)
sbnum = (lencurrently*(ucurrently-xbar)^2)+(lennever*(unever-xbar)^2)+(lenpreviously*(upreviously-xbar)^2)
print(paste("Analysis of Variance Table"))
an_table <- matrix(c(n1, sbnum, sb, f,p_value, swden, swnum, sw,'-','-' , n2-1, sst,'-','-','-'  ), ncol=5, byrow=TRUE)
colnames(an_table) <- c('Df','Sum of Sq','Mean Sq','F value','Pr(>F)')
rownames(an_table) <- c('X (Between)','Residuals (Within (Error))', 'Total')
an_table <- as.table(an_table)
an_table
```
    
      F val = 72.452
    P val = 2.2e-16 from R function and 0 from Anova table made manually. 
    P values are small and so reject null hypothesis . Average age are different 
    in atleast two groups
    
    c. Further explore the results using a Bonferroni multiple comparison 
    procedure with overall familywise error rate of $\alpha_{FWE}=0.05$. For this
    part, use the `pairwise.t.test()` function with `p.adj="bonferroni"`.
    
    Null Hypothesis: Average age in these groups are same.
    H1 : Average age in these groups are different. Average age are different 
    in atleast two groups
    
```{r}
Y = actg$Age
X = actg$IVDrug
pairwise.t.test(Y, X, p.adj = "bonferroni")
```
    
    P val for Never, Currently is 2e-16
    P val for Previously, Currently is 2e-16
    P val for Previously, Never is 0.0036
    
    P values are small and so reject null hypothesis . Average age are different 
    in every groups
    
    
    d. As an alternative approach to Bonferroni's multiple comparison adjustment,
    we will explore explore Scheffe's method for multiple comparisons. Scheffe's 
    method is a more general method that does not depend on the number of 
    comparisons being made (whereas Bonferroni directly adjust for that in doing 
    $\alpha/k$ as the significance level). With Scheffe's method, the 
    experimentwise error rate is $\alpha$ (i.e. the overall significance level),
    and it ensure that the probability of declaring at least one false significant
    comparison is at most $\alpha$. This method is preferable to Bonferroni
    particularly in cases when you are looking at many comparisons. For more 
    information about Scheffe's method I would recommend taking a look at the video here: https://www.youtube.com/watch?v=l6i0xhnIzzk. Essentially, though, this is just 
    another approach for testing for multiple comparisons. **For this question,
    implement Scheffe's method to test for significant pairwise differences at 
    the experimentwise error rate of $\alpha=0.05$, and interpret the results.**
    To do Scheffe's method, you first need to go to the R Console (i.e. not
    directly in your .RMD document) and install the `DescTools` package. Then, 
    in your .RMD document, load the package into R using `library(DescTools)`. 
    The `ScheffeTest()` function will allow you to perform Scheffe's method of 
    multiple comparisons. Look at `help(ScheffeTest)` for more information, but 
    generally, you will put your `aov` object into the `ScheffeTest()` function,
    and it will look for significant pairwise comparisons.
    
   
    Null Hypothesis: Average age in these groups are same.
    H1 : Average age in these groups are different.Average age are different 
    in atleast two groups
    
```{r}
library(DescTools)
ScheffeTest(Y, X, conf.level = 0.95)
```
    
    P val for Never-Currently is 2e-16
    P val for Previously-Currently is 2e-16
    P val for Previously-Never is 0.0053
    All p values are small and so reject null hypo . Average age are different 
    in every groups
    

The rest of the questions in this homework assignment rely on the following 
premise. Suppose a nonprofit organization is looking to analyze trends among its
donors, and they have collected data in "donors.csv". In particular, suppose they
have a sample of 94 donors who gave a gift in response to a recent solicitation. 
Suppose you have been hired by the organization to analyze trends among the donors.
We ultimately are interested in predicting donation amount based on other factors.
Begin by predicting donation amount (`amount`) based on the income a donor is 
making (`income`).  


2. Let's begin with exploratory analysis.

```{r}
donors <-  read.csv('donors.csv.')
head(donors)
```

    a. State the regression assumptions in terms of the variables we are investigating. 
    
1) Given (income, age , sex, time) and amount are independent
2) There is linear relationship between amount and (income, age , sex, time)
3)The variance is constant across all values of (income, age , sex, time), known as
homoscedasticity
4)For a specified value of (income, age , sex, time), amount is normally distributed
5)(income, age , sex, time)are fixed, known quantities



    b. What is the Pearson correlation between the donation amount and income?
```{r}
x = donors$income
y = donors$amount
cor.test(x, y, method = c("pearson"))
```
    0.9185 is the Pearson correlation between the donation amount and income
    

    c. Construct a scatterplot of donation amount over income. Comment on whether
    linear regression seems appropriate.
    
```{r}
plot(x, y, main="Scatterplot Donation anount over Income",   xlab="Income ", ylab="Amount ", pch=10)
abline(lm(y~x), col="red")
lines(lowess(x,y), col="blue") 
```
    Yes, Linear Regression is possible
 
3. Now, let's move onto simple linear regression. 

    a. Using a simple linear regression analysis, calculate and report the
    prediction equation for donation amount as a function of income. 
    
```{r}
model1 <- lm(y~x)
model1
summary(model1)
```
```{r}
r = cor(x,y)
sdx = sd(x)
sdy = sd(y)
ux = mean(x)
uy = mean(y)
b1 = r*(sdy/sdx)
b1
b0 = uy - b1*ux
b0

```
    F- statistic = 496.4 
    p-value: < 2.2e-16
    b0 is1.128931
    b1 is 0.001623163
    ybar = b0 + b1*x
    amount = 1.128931 + 0.001623163*income
  
    b. What is the estimated mean donation amount for a donor with an income
    of \$92,000?
```{r}
xnew = 92000
ybar = b0 + b1*xnew
ybar
```
    150.46 is the estimated mean donation amount for a donor with an income
    of $92,000

    c.  What is the estimated mean donation amount for a donor with an income 
    of \$1,000,000?
    
```{r}
xnew = 1000000
ybar = b0 + b1*xnew
ybar
```
     1624.292 is the estimated mean donation amount for a donor with an income 
    of $1,000,000

    d. Do you feel equally comfortable making predictions for the previous
    two questions? Explain. 

No, income is way too high. Like predicting can be done but the model is trained
for incomes in range like 80-120k while 1,000,000 is way too high. For this 
level of income this model might not work.

    e. Create a 90\% confidence interval for average donation amount for a donor 
    with an income of \$86,000. Interpret the results. 
    You may find the `predict()` function useful. 
    
```{r}
uy
ux
model = lm(y~x)
predict(model, level = 0.9, newdata = data.frame(x=86000), interval="confidence")
```
(136.9608, 144.4811) is 90% confidence interval for average donation amount for a donor 
    with an income of $86,000

    f. Create a 90% prediction interval for average donation amount for a donor
    with an income of \$86,000. Interpret the results.
    
```{r}
predict(model, level = 0.9, newdata = data.frame(x=86000), interval="prediction")
```
  (104.4402, 177.0018)  is a 90% prediction interval for average donation amount
  for a donor with an income of $86,000

    g. Construct a 95\% confidence interval for the slope of the estimated
    regression equation and interpret the results. You may find the `confint()` 
    function useful.
    
```{r}
confint(model1)
```
    ( 0.001478471 , 0.001767856) is a 95% confidence interval for the
    slope of the estimated regression equation

    h. Test the hypothesis that $H_0:\beta_1=0$ versus $H_1:\beta_1 \ne 0$ at the
    $\alpha=0.05$ significance level. What conclusion do you reach in the context
    of the problem? Report the test statistic. You can refer to the summary of your
    linear regression model to answer this question.
    
    H0 : Beta1 is zero
    H1 : Beta1 is not zero
 
```{r}
summary(model1)
```
```{r}
beta1 = 0.001623
std_err = 0.00007285
df = 92
tstat = beta1/std_err
tstat
pval = 2*pt(-abs(tstat),df=92)
pval
```
 T Statistic is 22.27865
 P val = 7.697071e-39
 Reject null hypothesis. Beta1 is not zero. Income is significantly related to
 donation amount can be inferred.
 
 
    i. What is the value of the coefficient of determination? Interpret this
    result in the context of the question.
    
```{r}
summary(model1)$r.squared 
```
    0.8436422  is the value of the coefficient of determination

    j. Construct diagnostic plots (including a residual plot and a normal qq plot).
    Comment on the fit of the model with respect to the model assumptions from part a.
    
    
```{r}
plot(x, resid(model) , main="The Residual Plot",ylab="Residual Model", xlab="Income", col="blue")
abline(0,0)
```
    
```{r}
qqnorm(resid(model), col="blue")
qqline(resid(model), col="red")
```
Fit is very good, qqnorm follows qqline closely.
Normal distribution can be seen.
Multiple R-squared value is  0.8436,	Adjusted R-squared value is  0.8419 
F-statistic value is  496.4 on 1 and 92 DF,  p-value is  2.2e-16 also proves the
same


4. Now, let's move onto multiple linear regression. 

    a. Calculate the prediction equation for donation amount as a function of income, age, and sex. Report the prediction equation. 
```{r}
amount = donors$amount
income = donors$income
age = donors$age
sex = donors$sex

inc <-lm(amount~income)
summary(inc)

inc_age <-lm(amount~income+age)
summary(inc_age)

inc_sex <-lm(amount~income+sex)
summary(inc_sex)

all_fact <-lm(amount~income+age+sex)
summary(all_fact)
```
```{r}
#y_male = 45.66 + 0.001636*income - 1.003*age + 4.913*male
#y_female = 45.66 + 0.001636*income - 1.003*age + 4.913*female
#male =1
#female = 0

```
 
Prediction equations are:

y_male = 45.66 + 0.001636*income - 1.003*age + 4.913*male
y_female = 45.66 + 0.001636*income - 1.003*age + 4.913*female
male =1
female = 0

y_male = 50.573 + 0.001636*income - 1.003*age
y_female = 45.66 + 0.001636*income - 1.003*age
 
    b. Use an F test at the $\alpha=0.05$ significance level to determine if `age` 
    and/or `sex` significantly add to the model, once we account for `income`.
    Make sure to state your hypotheses, report the test statistic, and interpret
    the results in the context of the problem. For this part, you may want to run 
    `anova` with both linear regression models you have previously made; it should
    look something like `anova(lm1, lm2)`.
    
H0: Adding new attribute makes model more significant
H1: Adding new attribute doesn't makes model more significant

```{r}

anova(inc,inc_sex)
anova(inc, inc_age)
anova(inc,all_fact)
```

For income + sex
F val = 3.1146
P val = 0.08095 

For income + age
F val = 20.683 
P val = 1.667e-05

For income + age + sex
F val = 11.068 
P val = 5.04e-05

Age significantly adds to the model and Age + Sex also significantly add to the
model as P values in both the cases are very very low.

Short Answers:

  * About how long did this assignment take you? Did you feel it was too long, 
  too short, or reasonable? 
  5-6 hours including reading slides.
  
  * Who, if anyone, did you work with on this assignment?
   No one
  
  * What questions do you have relating to any of the material we have covered
  so far in class?  
  Anova, Simple Linear Regression, Multiple Linear Regression, Bonferroni
  multiple comparison 
    procedure